import openai
import os
from dotenv import load_dotenv
from db import find_answer, save_answer  # âœ… ë°˜ë“œì‹œ ìˆ˜ì •ëœ find_answer ì‚¬ìš©

load_dotenv()
openai.api_key = os.getenv("OPENAI_API_KEY")

# gpt ê¸°ë°˜ ì‘ë‹µ --------------------------------------------------------------------
def ask_question(question, car_model="ì•„ë°˜ë–¼"):
    # 1. DBì—ì„œ ë¨¼ì € ì°¾ê¸°
    answer, source = find_answer(question, car_model)

    if answer:
        print(f"\nğŸ“¦ DB Response (source: {source}):")
        print(answer)
        return answer  # âœ… GPT í˜¸ì¶œ ìƒëµ

    # 2. GPTë¡œ ìƒì„±
    print("âŒ Not in DB. Asking GPT...")
    response = openai.chat.completions.create(
        model="gpt-3.5-turbo",
        messages=[
            {"role": "system", "content": f"You are a car assistant for model: {car_model}."},
            {"role": "user", "content": question}
        ]
    )
    answer = response.choices[0].message.content.strip()

    # 3. GPTê°€ ìƒì„±í•œ ë‹µë³€ ì €ì¥ (chat_log + solution)
    save_answer(question, answer, car_model)

    # 4. GPT ì‘ë‹µ ì¶œë ¥
    print("\nğŸ’¬ GPT Response:")
    print(answer)
    return answer

# ì‹¤í–‰ ë¶€ë¶„ --------------------------------------------------------------------
if __name__ == "__main__":
    print("ğŸš˜ ì°¨ëŸ‰ AI ë¹„ì„œì—ê²Œ ì§ˆë¬¸í•˜ì„¸ìš”! (ì¢…ë£Œí•˜ë ¤ë©´ 'ì¢…ë£Œ'ë¼ê³  ì…ë ¥í•˜ì„¸ìš”)\n")

    car_model = input("ğŸš— ì°¨ëŸ‰ ëª¨ë¸ì„ ì…ë ¥í•˜ì„¸ìš”: ")

    while True:
        question = input("\nâ“ ì§ˆë¬¸: ")

        if question.strip().lower() in ['ì¢…ë£Œ', 'exit', 'quit']:
            print("ğŸ‘‹ ì¢…ë£Œí•©ë‹ˆë‹¤. ì•ˆì „ ìš´ì „ í•˜ì„¸ìš”!")
            break

        ask_question(question, car_model)
    
# ë””ë¹„ì—ì„œë§Œ ê²€ìƒ‰ ------------------------------------------------------------------------------------------- 
# from db import search_all_tables
# import os

# def ask_anything(question):
#     result = search_all_tables(question)

#     if result:
#         print("âœ… Found in DB:")
#         return result
#     else:
#         print("âŒ DBì— ê´€ë ¨ ì •ë³´ê°€ ì—†ìŠµë‹ˆë‹¤.")
#         return "ì£„ì†¡í•©ë‹ˆë‹¤. ì§ˆë¬¸ì— í•´ë‹¹í•˜ëŠ” ì •ë³´ë¥¼ ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."

# if __name__ == "__main__":
#     question = input("â“ Question: ")
#     response = ask_anything(question)
#     print("\nğŸ“˜ Response:")
#     print(response)
# ë””ë¹„ + ì³‡ ê²€ìƒ‰ê²°ê³¼ ë³‘í•© ------------------------------------------------------------------------------
# import openai
# import os
# from dotenv import load_dotenv
# from db import search_all_tables

# # í™˜ê²½ë³€ìˆ˜ ë¡œë”© (.env íŒŒì¼)
# load_dotenv()
# openai.api_key = os.getenv("OPENAI_API_KEY")

# # âœ… DB + GPT ë³‘í•© ì‘ë‹µ í•¨ìˆ˜
# def ask_question_combined(question):
#     # 1. ë¨¼ì € DBì—ì„œ ê²€ìƒ‰
#     db_result = search_all_tables(question)
    
#     # 2. GPTì—ê²Œë„ í•­ìƒ ì§ˆë¬¸í•´ì„œ ë³´ì™„ ì„¤ëª… ë°›ê¸°
#     print("ğŸ¤– GPTì—ë„ ì§ˆë¬¸ ì¤‘...")
#     gpt_response = openai.chat.completions.create(
#         model="gpt-3.5-turbo",
#         messages=[
#             {"role": "system", "content": "ë„ˆëŠ” ìë™ì°¨ ì •ë¹„, ê²½ê³ ë“±, ì‘ê¸‰ìƒí™© ë“±ì— ëŒ€í•´ ì„¤ëª…í•´ì£¼ëŠ” AI ë„ìš°ë¯¸ì•¼."},
#             {"role": "user", "content": question}
#         ]
#     )
#     gpt_result = gpt_response.choices[0].message.content.strip()

#     # 3. ë³‘í•©ëœ ì‘ë‹µ ë°˜í™˜
#     if db_result:
#         return f"""ğŸ“˜ [ë°ì´í„°ë² ì´ìŠ¤ì— ìˆëŠ” ì •ë³´]
# {db_result}

# ğŸ¤– [GPTê°€ ë³´ì™„í•œ ì„¤ëª…]
# {gpt_result}
# """
#     else:
#         return f"""â—ï¸ë°ì´í„°ë² ì´ìŠ¤ì— ì§ì ‘ì ì¸ ì •ë³´ëŠ” ì—†ì—ˆìŠµë‹ˆë‹¤.

# ğŸ¤– [GPTê°€ ì œê³µí•˜ëŠ” ì„¤ëª…]
# {gpt_result}
# """

# # âœ… ë©”ì¸ ì‹¤í–‰
# if __name__ == "__main__":
#     question = input("â“ Question: ")
#     response = ask_question_combined(question)
#     print(response)

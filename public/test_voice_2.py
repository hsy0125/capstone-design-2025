# from google.cloud import speech
# from dotenv import load_dotenv
# import os
# import pyaudio
# import wave
# from voice_db import find_voice_answer, save_voice_answer
# import openai
# from gtts import gTTS
# from playsound import playsound
# import re

# load_dotenv()
# os.environ["GOOGLE_APPLICATION_CREDENTIALS"] = os.getenv("GOOGLE_APPLICATION_CREDENTIALS")
# openai.api_key = os.getenv("OPENAI_API_KEY")

# def record_audio(filename="temp.wav", seconds=5):
#     RATE = 16000                                                    # ìƒ˜í”Œë§ë ˆì´íŠ¸ ì´ˆë‹¹16000í”„ë ˆì„
#     CHUNK = 1024                                                    # 1024í”„ë ˆì„
#     FORMAT = pyaudio.paInt16                                        # 16ë¹„íŠ¸ ì˜¤ë””ì˜¤ í¬ë©§
#     CHANNELS = 1                                                    # ì±„ë„ìˆ˜

#     print("ğŸ™ï¸ ë§í•´ì£¼ì„¸ìš”...")
#     p = pyaudio.PyAudio()                                           # PyAudio ê°ì²´ ìƒì„±
#     stream = p.open(format=FORMAT, channels=CHANNELS, rate=RATE,    # ì…ë ¥ìŠ¤íŠ¸ë¦¼ì„ ì„¤ì •í•´ ì˜¤ë””ì˜¤ì…ë ¥
#                     input=True, frames_per_buffer=CHUNK)

#     frames = []                                                     # 5ì´ˆë™ì•ˆ ì½ì–´ì„œ frames ë¦¬ìŠ¤íŠ¸ì— ì €ì¥
#     for _ in range(0, int(RATE / CHUNK * seconds)):
#         data = stream.read(CHUNK)
#         frames.append(data)

#     stream.stop_stream()                                            # ì…ë ¥ ì¢…ë£Œ
#     stream.close()
#     p.terminate()

#     with wave.open(filename, 'wb') as wf:                           # wavíŒŒì¼ìƒì„± ì €ì¥
#         wf.setnchannels(CHANNELS)
#         wf.setsampwidth(p.get_sample_size(FORMAT))
#         wf.setframerate(RATE)
#         wf.writeframes(b''.join(frames))
#     print("âœ… ë…¹ìŒ ì™„ë£Œ")

# def extract_main_content(text):
#     # ì„¤ëª…ê³¼ í•´ê²° ë°©ë²• ë˜ëŠ” ì‘ê¸‰ì¡°ì¹˜ ë‹¨ê³„ë§Œ ì¶”ì¶œ
#     ì„¤ëª… = re.search(r"âš ï¸ ì„¤ëª…:\n(.+?)\n\n", text, re.DOTALL)
#     í•´ê²° = re.search(r"ğŸ›  í•´ê²° ë°©ë²•:\n(.+)$", text, re.DOTALL)
#     ì‘ê¸‰ = re.search(r"ğŸ§­ ì‘ê¸‰ì¡°ì¹˜ ë‹¨ê³„:\n(.+)$", text, re.DOTALL)

#     if ì„¤ëª… or í•´ê²°:
#         parts = []
#         if ì„¤ëª…:
#             parts.append(ì„¤ëª….group(1).strip())
#         if í•´ê²°:
#             parts.append(í•´ê²°.group(1).strip())
#         return "\n".join(parts)
#     elif ì‘ê¸‰:
#         return ì‘ê¸‰.group(1).strip()
#     else:
#         return text

# def speak_text(text):
#     tts = gTTS(text=text, lang='ko')
#     tts.save("response.mp3")
#     playsound("response.mp3")

# def transcribe_and_answer(filename="temp.wav", car_model="ì•„ë°˜ë–¼"):
#     client = speech.SpeechClient()

#     with open(filename, 'rb') as audio_file:
#         audio_bytes = audio_file.read()

#     audio = speech.RecognitionAudio(content=audio_bytes)
#     config = speech.RecognitionConfig(
#         encoding=speech.RecognitionConfig.AudioEncoding.LINEAR16,
#         sample_rate_hertz=16000,
#         language_code="ko-KR"
#     )

#     response = client.recognize(config=config, audio=audio)

#     for result in response.results:
#         question = result.alternatives[0].transcript
#         print(f"ğŸ§  ì¸ì‹ëœ ì§ˆë¬¸: {question}")

#         # 1. DB ê²€ìƒ‰ ì‹œë„
#         answer = find_voice_answer(question)

#         # 2. GPT fallback
#         if not answer:
#             print("ğŸ¤– GPT í˜¸ì¶œ ì¤‘...")
#             gpt_response = openai.chat.completions.create(
#                 model="gpt-3.5-turbo",
#                 messages=[
#                     {"role": "system", "content": f"You are a car assistant for model: {car_model}."},
#                     {"role": "user", "content": question}
#                 ]
#             )
#             answer = gpt_response.choices[0].message.content.strip()
#             print("ğŸ’¬ GPT ì‘ë‹µ:")

#         # 3. ì¶œë ¥ ë° ì €ì¥ + ìŒì„± ì¬ìƒ (ë‚´ìš©ë§Œ ë§í•˜ê¸°)
#         print(answer)
#         speak_text(extract_main_content(answer))
#         save_voice_answer(question, answer, car_model)
#         print("âœ… ì§ˆë¬¸ê³¼ ë‹µë³€ ì €ì¥ ì™„ë£Œ")

# record_audio()
# transcribe_and_answer()

# test_voice_2.py  â€” ì°¨ëŸ‰ìš©í’ˆ í‚¤ì›Œë“œ ê°ì§€ â†’ ë„¤ì´ë²„ ì‡¼í•‘ ë§í¬ ìë™ ì²¨ë¶€ (ìŒì„±ì€ ë§í¬ ë¯¸ë‚­ë…)

from google.cloud import speech
from dotenv import load_dotenv
import os
import pyaudio
import wave
from voice_db import find_voice_answer, save_voice_answer
import openai
from gtts import gTTS
from playsound import playsound
import re
from urllib.parse import quote

# -------------------- ì„¤ì • --------------------
ACCESSORY_LINK_ONLY = False  # True: ë§í¬ë§Œ ì‘ë‹µ / False: ì›ë˜ ë‹µë³€ + ë§í¬ ë§ë¶™ì„
DEFAULT_CAR_MODEL = "ì•„ë°˜ë–¼"
SAMPLE_RATE = 16000
CHUNK = 1024
CHANNELS = 1

# -------------------- ì´ˆê¸°í™” --------------------
load_dotenv()
os.environ["GOOGLE_APPLICATION_CREDENTIALS"] = os.getenv("GOOGLE_APPLICATION_CREDENTIALS")
openai.api_key = os.getenv("OPENAI_API_KEY")

# -------------------- ìœ í‹¸ í•¨ìˆ˜ --------------------
def record_audio(filename="temp.wav", seconds=5):
    print("ğŸ™ï¸ ë§í•´ì£¼ì„¸ìš”...")
    p = pyaudio.PyAudio()
    stream = p.open(format=pyaudio.paInt16, channels=CHANNELS, rate=SAMPLE_RATE,
                    input=True, frames_per_buffer=CHUNK)
    frames = []
    for _ in range(0, int(SAMPLE_RATE / CHUNK * seconds)):
        data = stream.read(CHUNK)
        frames.append(data)
    stream.stop_stream()
    stream.close()
    p.terminate()
    with wave.open(filename, 'wb') as wf:
        wf.setnchannels(CHANNELS)
        wf.setsampwidth(p.get_sample_size(pyaudio.paInt16))
        wf.setframerate(SAMPLE_RATE)
        wf.writeframes(b''.join(frames))
    print("âœ… ë…¹ìŒ ì™„ë£Œ")

def extract_main_content(text: str) -> str:
    """ë‹µë³€ í¬ë§·(ì„¤ëª…/í•´ê²°/ì‘ê¸‰ë‹¨ê³„)ì´ ìˆì„ ê²½ìš° í•µì‹¬ë§Œ ì¶”ì¶œí•´ì„œ ìŒì„±ìœ¼ë¡œ ì½ê¸° ì¢‹ê²Œ ì •ë¦¬."""
    ì„¤ëª… = re.search(r"âš ï¸ ì„¤ëª…:\n(.+?)\n\n", text, re.DOTALL)
    í•´ê²° = re.search(r"ğŸ›  í•´ê²° ë°©ë²•:\n(.+)$", text, re.DOTALL)
    ì‘ê¸‰ = re.search(r"ğŸ§­ ì‘ê¸‰ì¡°ì¹˜ ë‹¨ê³„:\n(.+)$", text, re.DOTALL)
    if ì„¤ëª… or í•´ê²°:
        parts = []
        if ì„¤ëª…: parts.append(ì„¤ëª….group(1).strip())
        if í•´ê²°: parts.append(í•´ê²°.group(1).strip())
        return "\n".join(parts)
    elif ì‘ê¸‰:
        return ì‘ê¸‰.group(1).strip()
    return text

def speak_text(text: str):
    """gTTSë¡œ ìŒì„± ì¬ìƒ"""
    tts = gTTS(text=text, lang='ko')
    tts.save("response.mp3")
    playsound("response.mp3")

# -------------------- ì°¨ëŸ‰ìš©í’ˆ í‚¤ì›Œë“œ & ë§í¬ --------------------
def detect_accessory_keyword(text: str):
    """ì§ˆë¬¸ì—ì„œ ì°¨ëŸ‰ìš©í’ˆ ê´€ë ¨ í‚¤ì›Œë“œ ê°ì§€"""
    kw_map = {
        "íƒ€ì´ì–´": ["íƒ€ì´ì–´", "ìŠ¤ë…¸ìš°íƒ€ì´ì–´", "íœ ", "ê³µê¸°ì••"],
        "ì—”ì§„ì˜¤ì¼": ["ì—”ì§„ì˜¤ì¼", "ì˜¤ì¼", "ì˜¤ì¼í•„í„°"],
        "ì™€ì´í¼": ["ì™€ì´í¼", "ì™€ì´í¼ë¸”ë ˆì´ë“œ"],
        "ë°°í„°ë¦¬": ["ë°°í„°ë¦¬", "ì¶•ì „ì§€"],
        "ë¸”ë™ë°•ìŠ¤": ["ë¸”ë™ë°•ìŠ¤", "ëŒ€ì‹œìº "],
        "ë„¤ë¹„ê²Œì´ì…˜": ["ë„¤ë¹„", "ë„¤ë¹„ê²Œì´ì…˜", "ë‚´ë¹„"],
        "ì—ì–´í•„í„°": ["ì—ì–´í•„í„°", "ìºë¹ˆí•„í„°", "ê³µì¡°í•„í„°", "ì—ì–´ì»¨í•„í„°"],
        "ì²´ì¸": ["ì²´ì¸", "ìŠ¤ë…¸ìš°ì²´ì¸"],
        "ì„¸ì°¨ìš©í’ˆ": ["ì„¸ì°¨", "ì™ìŠ¤", "ê´‘íƒ", "í¼ê±´", "ì›Œì‹œ"],
        "ë°©í–¥ì œ": ["ë°©í–¥ì œ", "íƒˆì·¨"],
        "ì¶©ì „ê¸°": ["ì¶©ì „ê¸°", "ì‹œê±°ì­", "USBì¶©ì „ê¸°", "usb ì¶©ì „ê¸°"],
        # í•„ìš” ì‹œ ê³„ì† ì¶”ê°€
    }
    lower = text.lower()
    for key, alts in kw_map.items():
        for alt in alts:
            if alt in text or alt.lower() in lower:
                return key
    return None

def build_naver_shopping_link(keyword: str, car_model: str | None = None) -> str:
    query = f"{car_model} {keyword}" if car_model else keyword
    return f"https://search.shopping.naver.com/search/all?query={quote(query)}"

# -------------------- ë©”ì¸ ë¡œì§ --------------------
def transcribe_and_answer(filename="temp.wav", car_model: str = DEFAULT_CAR_MODEL):
    client = speech.SpeechClient()
    with open(filename, 'rb') as f:
        audio_bytes = f.read()

    audio = speech.RecognitionAudio(content=audio_bytes)
    config = speech.RecognitionConfig(
        encoding=speech.RecognitionConfig.AudioEncoding.LINEAR16,
        sample_rate_hertz=SAMPLE_RATE,
        language_code="ko-KR",
    )

    response = client.recognize(config=config, audio=audio)

    for result in response.results:
        question = result.alternatives[0].transcript
        print(f"ğŸ§  ì¸ì‹ëœ ì§ˆë¬¸: {question}")

        # 1) DBì—ì„œ ìš°ì„  ë‹µë³€ ì°¾ê¸°
        answer = find_voice_answer(question)

        # 2) ì—†ìœ¼ë©´ GPTë¡œ ë³´ì™„
        if not answer:
            print("ğŸ¤– GPT í˜¸ì¶œ ì¤‘...")
            gpt_response = openai.chat.completions.create(
                model="gpt-3.5-turbo",
                messages=[
                    {"role": "system", "content": f"You are a car assistant for model: {car_model}."},
                    {"role": "user", "content": question}
                ]
            )
            answer = gpt_response.choices[0].message.content.strip()
            print("ğŸ’¬ GPT ì‘ë‹µ:")

        # 3) ì°¨ëŸ‰ìš©í’ˆ í‚¤ì›Œë“œë©´ ë„¤ì´ë²„ ì‡¼í•‘ ë§í¬ ì¶”ê°€/ëŒ€ì²´
        keyword = detect_accessory_keyword(question)
        if keyword:
            link = build_naver_shopping_link(keyword, car_model)
            if ACCESSORY_LINK_ONLY:
                answer = f"{keyword} ê´€ë ¨ ë„¤ì´ë²„ ì‡¼í•‘ ë§í¬ì…ë‹ˆë‹¤:\n{link}"
            else:
                answer = f"{answer}\n\nğŸ›’ ê´€ë ¨ ìš©í’ˆ ì‡¼í•‘: {link}"

        # 4) ì¶œë ¥ + ìŒì„± ì¬ìƒ(ë§í¬ëŠ” ìŒì„±ì—ì„œ ì œê±°) + ì €ì¥
        print(answer)
        spoken = extract_main_content(answer)
        spoken = re.sub(r"https?://\S+", "", spoken)  # ìŒì„±ì—ì„œëŠ” URL ì œê±°
        speak_text(spoken)

        save_voice_answer(question, answer, car_model)
        print("âœ… ì§ˆë¬¸ê³¼ ë‹µë³€ ì €ì¥ ì™„ë£Œ")

# -------------------- ì‹¤í–‰ --------------------
if __name__ == "__main__":
    print("ğŸ§ ìŒì„± ê¸°ë°˜ ì°¨ëŸ‰ AI ë¹„ì„œ (DB ìš°ì„  + GPT ë³´ì™„ + ë„¤ì´ë²„ ì‡¼í•‘ ë§í¬)\n")
    print(f"ğŸš— ê¸°ë³¸ ì°¨ëŸ‰ ëª¨ë¸: {DEFAULT_CAR_MODEL}")
    record_audio()               # 5ì´ˆ ë…¹ìŒ
    transcribe_and_answer()      # ìŒì„± ì¸ì‹ â†’ ë‹µë³€ ìƒì„±/ì¬ìƒ/ì €ì¥

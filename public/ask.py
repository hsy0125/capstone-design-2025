import openai
import os
from dotenv import load_dotenv
from db import find_similar_answer, save_answer
from utils import normalize_question, is_similar
## GPT í˜¸ì¶œ, DB ê²€ìƒ‰ í†µí•©, ì¤‘ë³µ ë°©ì§€, ì¶œë ¥ ì œì–´

load_dotenv()
openai.api_key = os.getenv("OPENAI_API_KEY")

def ask_question(question, car_model="ì•„ë°˜ë–¼"):
    norm_question = normalize_question(question)

    # 1. DB ìœ ì‚¬ë„ ê²€ìƒ‰
    answer, source, matched_q = find_similar_answer(norm_question, car_model)

    if answer:
        print(f"\nğŸ“¦ DB Response (from {source}):\n(Q: {matched_q})")
        print(answer)

        use_gpt = input("\nğŸ¤– GPT ë³´ì™„ ì„¤ëª…ì„ ì¶”ê°€ë¡œ ë“¤ì„ê¹Œìš”? (Y/N): ").strip().lower()
        if use_gpt != 'y':
            return answer

    # 2. GPT ìƒì„±
    print("ğŸ§  GPT ìƒì„± ì¤‘...")
    prompt = f"""ë‹¹ì‹ ì€ ì°¨ëŸ‰ ëª¨ë¸ '{car_model}'ì— ëŒ€í•œ AI ì •ë¹„ ë„ìš°ë¯¸ì…ë‹ˆë‹¤.
ì§ˆë¬¸ì— ëŒ€í•´ ìš´ì „ìê°€ ì‰½ê²Œ ì´í•´í•  ìˆ˜ ìˆë„ë¡ ê°„ê²°í•˜ê³  ëª…í™•í•˜ê²Œ ì„¤ëª…í•´ì£¼ì„¸ìš”.

[ë‹µë³€ í˜•ì‹ ì˜ˆì‹œ]
âš ï¸ ì„¤ëª…: ì—”ì§„ì˜¤ì¼ ë¶€ì¡±ì„ ì•Œë¦¬ëŠ” ê²½ê³ ë“±ì…ë‹ˆë‹¤.
ğŸ›  í•´ê²° ë°©ë²•: ì°¨ëŸ‰ì„ ì •ì°¨í•œ í›„, ì—”ì§„ì˜¤ì¼ì„ ì ê²€í•˜ê³  ë³´ì¶©í•˜ì„¸ìš”.

ë‹µë³€ ë§ˆì§€ë§‰ì— ì°¸ê³  ì•ˆë‚´ ë¬¸êµ¬ë„ í¬í•¨í•˜ì„¸ìš”."""

    response = openai.chat.completions.create(
        model="gpt-3.5-turbo",
        messages=[
            {"role": "system", "content": prompt},
            {"role": "user", "content": question}
        ]
    )
    gpt_answer = response.choices[0].message.content.strip()

    # ì¶œì²˜ ë¬¸êµ¬ ì¶”ê°€
    gpt_answer += "\n\nğŸ” ì°¸ê³ : ì´ ì •ë³´ëŠ” ì¼ë°˜ì ì¸ ê¸°ì¤€ì— ê¸°ë°˜í•œ ì„¤ëª…ì´ë©°, ì°¨ëŸ‰ ë§¤ë‰´ì–¼ì„ í•¨ê»˜ ì°¸ê³ í•˜ì„¸ìš”."

    print("\nğŸ’¬ GPT ì‘ë‹µ:")
    print(gpt_answer)

    # DB ì €ì¥
    save_answer(norm_question, gpt_answer, car_model)
    return gpt_answer
from google.cloud import speech
from dotenv import load_dotenv
import os
import pyaudio
import wave
from db import save_answer  # DB ì €ì¥ í•¨ìˆ˜ë§Œ ì‚¬ìš©

load_dotenv()
os.environ["GOOGLE_APPLICATION_CREDENTIALS"] = os.getenv("GOOGLE_APPLICATION_CREDENTIALS")  #êµ¬ê¸€api í˜¸ì¶œ ì¸ì¦

def record_audio(filename="temp.wav", seconds=5):  #5ì´ˆë™ì•ˆ ìŒì„±ë°›ì•„ ì €ì¥
    RATE = 16000
    CHUNK = 1024                                    #16000Hz, 16bit, mono ì±„ë„ êµ¬ì„± (Google STT ê¸°ë³¸ ê¶Œì¥ ì„¤ì •)
    FORMAT = pyaudio.paInt16
    CHANNELS = 1

    print("ğŸ™ï¸ ë§í•´ì£¼ì„¸ìš”...")
    p = pyaudio.PyAudio()
    stream = p.open(format=FORMAT, channels=CHANNELS, rate=RATE,
                    input=True, frames_per_buffer=CHUNK)

    frames = []
    for _ in range(0, int(RATE / CHUNK * seconds)):
        data = stream.read(CHUNK)
        frames.append(data)

    stream.stop_stream()
    stream.close()
    p.terminate()

    with wave.open(filename, 'wb') as wf:
        wf.setnchannels(CHANNELS)
        wf.setsampwidth(p.get_sample_size(FORMAT))
        wf.setframerate(RATE)
        wf.writeframes(b''.join(frames))
    print("âœ… ë…¹ìŒ ì™„ë£Œ")

def transcribe_and_save(filename="temp.wav", car_model="ì•„ë°˜ë°"):
    client = speech.SpeechClient()

    with open(filename, 'rb') as audio_file:
        audio_bytes = audio_file.read()

    audio = speech.RecognitionAudio(content=audio_bytes)
    config = speech.RecognitionConfig(
        encoding=speech.RecognitionConfig.AudioEncoding.LINEAR16,
        sample_rate_hertz=16000,
        language_code="ko-KR"
    )

    response = client.recognize(config=config, audio=audio)

    for result in response.results:
        question = result.alternatives[0].transcript
        print(f"ğŸ§  ì¸ì‹ëœ ì§ˆë¬¸: {question}")

        # ì‘ë‹µ ì—†ì´ ì €ì¥ë§Œ ìˆ˜í–‰
        save_answer(question, "(ì‘ë‹µ ì—†ìŒ - ê¸°ë¡ ëª©ì )", car_model)
        print("ğŸ“ ì§ˆë¬¸ ì €ì¥ ì™„ë£Œ")

record_audio()
transcribe_and_save()
